{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e13745",
   "metadata": {},
   "source": [
    "# üß† Ultra Institutional AI Notebook ‚Äì Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================\n",
    "# üß© ULTRA INSTITUTIONAL AI ‚Äì MASTER TOP-DOWN SIGNAL\n",
    "# =========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "ultra_tf = [\"1M\",\"2M\",\"3M\",\"6M\",\"1Y\"]\n",
    "higher_tf = [\"1D\",\"4H\",\"1H\"]\n",
    "lower_tf  = [\"5M\",\"1M\",\"30s\"]\n",
    "all_tfs = ultra_tf + higher_tf + lower_tf\n",
    "\n",
    "def fetch_data(exchange, symbol, tf, limit=200):\n",
    "    df = exchange.get_klines(symbol, tf, limit)\n",
    "    return df\n",
    "\n",
    "def add_institutional_indicators(df):\n",
    "    df[\"ema_9\"]  = df[\"close\"].ewm(span=9).mean()\n",
    "    df[\"ema_21\"] = df[\"close\"].ewm(span=21).mean()\n",
    "    df[\"ema_50\"] = df[\"close\"].ewm(span=50).mean()\n",
    "    delta = df[\"close\"].diff()\n",
    "    gain, loss = delta.clip(lower=0), -delta.clip(upper=0)\n",
    "    df[\"rsi\"] = 100 - (100 / (1 + gain.rolling(14).mean() / (loss.rolling(14).mean() + 1e-9)))\n",
    "    df[\"macd\"] = df[\"close\"].ewm(span=12).mean() - df[\"close\"].ewm(span=26).mean()\n",
    "    df[\"macd_signal\"] = df[\"macd\"].ewm(span=9).mean()\n",
    "    tr = pd.concat([df[\"high\"]-df[\"low\"], abs(df[\"high\"]-df[\"close\"].shift()), abs(df[\"low\"]-df[\"close\"].shift())], axis=1).max(axis=1)\n",
    "    df[\"atr\"] = tr.rolling(14).mean()\n",
    "    sma20 = df[\"close\"].rolling(20).mean()\n",
    "    std20 = df[\"close\"].rolling(20).std()\n",
    "    df[\"bb_upper\"] = sma20 + 2*std20\n",
    "    df[\"bb_lower\"] = sma20 - 2*std20\n",
    "    hl2 = (df[\"high\"] + df[\"low\"])/2\n",
    "    factor = 3\n",
    "    df[\"supertrend_upper\"] = hl2 + factor*df[\"atr\"]\n",
    "    df[\"supertrend_lower\"] = hl2 - factor*df[\"atr\"]\n",
    "    df['hammer'] = ((df['close'] > df['open']) & ((df['low'] - df[['open','close']].min(axis=1)) > 2*(df['close']-df['open']))).astype(int)\n",
    "    df['doji'] = (abs(df['close'] - df['open']) <= 0.1*(df['high'] - df['low'])).astype(int)\n",
    "    df['engulfing_bull'] = ((df['close'] > df['open'].shift()) & (df['open'] < df['close'].shift())).astype(int)\n",
    "    df['momentum_score'] = df['hammer'] + df['doji'] + df['engulfing_bull']\n",
    "    df.fillna(method=\"bfill\", inplace=True)\n",
    "    df.fillna(method=\"ffill\", inplace=True)\n",
    "    return df\n",
    "\n",
    "def evaluate_strategies(df):\n",
    "    scores = {}\n",
    "    scores['breakout'] = 0.85 if df['macd'].iloc[-1] > df['macd_signal'].iloc[-1] else 0.7\n",
    "    scores['mean_reversion'] = 0.8 if df['rsi'].iloc[-1] < 30 else 0.6\n",
    "    scores['momentum_reversal'] = df['momentum_score'].iloc[-1]/3\n",
    "    return scores\n",
    "\n",
    "def evaluate_indicators(df):\n",
    "    scores = {}\n",
    "    scores['ema_align'] = 0.9 if df['ema_9'].iloc[-1] > df['ema_21'].iloc[-1] else 0.7\n",
    "    scores['atr_spike'] = 0.85 if df['atr'].iloc[-1] > df['atr'].rolling(14).mean().iloc[-1]*1.5 else 0.6\n",
    "    return scores\n",
    "\n",
    "def news_sentiment_score(symbol):\n",
    "    return 0.85\n",
    "\n",
    "def top_down_alignment(exchange, symbol):\n",
    "    tf_results = {}\n",
    "    for tf in all_tfs:\n",
    "        df = fetch_data(exchange, symbol, tf)\n",
    "        if df.empty: continue\n",
    "        df = add_institutional_indicators(df)\n",
    "        strat_scores = evaluate_strategies(df)\n",
    "        ind_scores = evaluate_indicators(df)\n",
    "        combined_scores = {**{k:v for k,v in strat_scores.items() if v>=0.8},\n",
    "                           **{k:v for k,v in ind_scores.items() if v>=0.8}}\n",
    "        tf_results[tf] = combined_scores\n",
    "    selected_tfs = sorted(tf_results, key=lambda x: np.mean(list(tf_results[x].values() or [0])), reverse=True)[:5]\n",
    "    final_alignment = {}\n",
    "    for tf in selected_tfs:\n",
    "        final_alignment.update(tf_results[tf])\n",
    "    final_alignment['news_sentiment'] = news_sentiment_score(symbol)\n",
    "    return final_alignment, selected_tfs\n",
    "\n",
    "def execute_trade(exchange, symbol, alignment, selected_tfs):\n",
    "    leverage = 10 if selected_tfs[0] in ultra_tf + higher_tf else 5\n",
    "    df_low = fetch_data(exchange, symbol, lower_tf[0])\n",
    "    entry_price = df_low['close'].iloc[-1]\n",
    "    df_low = add_institutional_indicators(df_low)\n",
    "    atr = df_low['atr'].iloc[-1]\n",
    "    tp = entry_price + atr*1.5\n",
    "    sl = entry_price - atr*1.5\n",
    "    trade_decision = {\n",
    "        \"symbol\": symbol,\n",
    "        \"entry\": entry_price,\n",
    "        \"tp\": tp,\n",
    "        \"sl\": sl,\n",
    "        \"leverage\": leverage,\n",
    "        \"alignment\": alignment,\n",
    "        \"selected_tfs\": selected_tfs,\n",
    "        \"timestamp\": datetime.utcnow().isoformat()\n",
    "    }\n",
    "    return trade_decision\n",
    "\n",
    "# Example (commented):\n",
    "# alignment, selected_tfs = top_down_alignment(exchange, \"BTCUSDT\")\n",
    "# trade_decision = execute_trade(exchange, \"BTCUSDT\", alignment, selected_tfs)\n",
    "# print(\"Trade decision:\", trade_decision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43321fdd",
   "metadata": {},
   "source": [
    "## üîÅ Candle Learning Module (CLM) ‚Äî Integrated\n",
    "This cell contains the candle pattern detector, reinforcement update logic, and helper functions to integrate candle confidence into the master top-down alignment. The CLM stores pattern performance to `/mnt/data/candle_stats.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1108f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Path to store pattern stats\n",
    "CANDLE_STATS_PATH = \"/mnt/data/candle_stats.json\"\n",
    "\n",
    "# Initialize stats file if missing\n",
    "def _ensure_stats_file():\n",
    "    if not os.path.exists(CANDLE_STATS_PATH):\n",
    "        init = {}\n",
    "        # initialize common patterns with neutral stats\n",
    "        patterns = [\"bullish_engulfing\",\"bearish_engulfing\",\"hammer\",\"hanging_man\",\"pinbar\",\"doji\",\"marubozu\",\"morning_star\",\"evening_star\",\"tweezers_top\",\"tweezers_bottom\"]\n",
    "        for p in patterns:\n",
    "            init[p] = {\"success_rate\": 0.5, \"count\": 0, \"wins\": 0, \"losses\": 0}\n",
    "        with open(CANDLE_STATS_PATH, \"w\") as f:\n",
    "            json.dump(init, f, indent=2)\n",
    "\n",
    "_ensure_stats_file()\n",
    "\n",
    "def load_candle_stats():\n",
    "    with open(CANDLE_STATS_PATH, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_candle_stats(stats):\n",
    "    with open(CANDLE_STATS_PATH, \"w\") as f:\n",
    "        json.dump(stats, f, indent=2)\n",
    "\n",
    "# --- Pattern detection routines ---\n",
    "def detect_patterns_from_df(df):\n",
    "    \\\"\\\"\\\"Detect common candle patterns on the last 3 bars and return pattern signals and raw indicators.\\\"\\\"\\\"\n",
    "    # Ensure required cols exist\n",
    "    for col in [\"open\",\"high\",\"low\",\"close\",\"volume\"]:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\\\"Missing required column: {col}\\\")\n",
    "    last = df.iloc[-3:].copy().reset_index(drop=True)  # work with last 3 for multi-bar patterns\n",
    "    patterns_found = defaultdict(int)\n",
    "    # Single bar metrics\n",
    "    last['body'] = (last['close'] - last['open']).abs()\n",
    "    last['upper_wick'] = last['high'] - last[['close','open']].max(axis=1)\n",
    "    last['lower_wick'] = last[['close','open']].min(axis=1) - last['low']\n",
    "    last['range'] = last['high'] - last['low'] + 1e-9\n",
    "    last['body_ratio'] = last['body'] / last['range']\n",
    "\n",
    "    # Detect doji (last bar)\n",
    "    if last.loc[2,'body_ratio'] <= 0.1:\n",
    "        patterns_found['doji'] += 1\n",
    "\n",
    "    # Detect hammer / hanging man (last bar)\n",
    "    if last.loc[2,'body_ratio'] < 0.4 and last.loc[2,'lower_wick'] > 2 * last.loc[2,'body']:\n",
    "        # bullish if close > open\n",
    "        if last.loc[2,'close'] > last.loc[2,'open']:\n",
    "            patterns_found['hammer'] += 1\n",
    "        else:\n",
    "            patterns_found['hanging_man'] += 1\n",
    "\n",
    "    # Engulfing (2-bar)\n",
    "    if (last.loc[1,'close'] < last.loc[1,'open']) and (last.loc[2,'close'] > last.loc[2,'open']) and (last.loc[2,'open'] < last.loc[1,'close']) and (last.loc[2,'close'] > last.loc[1,'open']):\n",
    "        patterns_found['bullish_engulfing'] += 1\n",
    "    if (last.loc[1,'close'] > last.loc[1,'open']) and (last.loc[2,'close'] < last.loc[2,'open']) and (last.loc[2,'open'] > last.loc[1,'close']) and (last.loc[2,'close'] < last.loc[1,'open']):\n",
    "        patterns_found['bearish_engulfing'] += 1\n",
    "\n",
    "    # Pinbar (long upper or lower wick relative to body)\n",
    "    if last.loc[2,'upper_wick'] > 3 * last.loc[2,'body']:\n",
    "        patterns_found['pinbar_upper'] += 1\n",
    "    if last.loc[2,'lower_wick'] > 3 * last.loc[2,'body']:\n",
    "        patterns_found['pinbar_lower'] += 1\n",
    "\n",
    "    # Marubozu (very small wicks)\n",
    "    if last.loc[2,'upper_wick'] < 0.05*last.loc[2,'range'] and last.loc[2,'lower_wick'] < 0.05*last.loc[2,'range'] and last.loc[2,'body_ratio']>0.8:\n",
    "        patterns_found['marubozu'] += 1\n",
    "\n",
    "    # Tweezer bottom/top (2-bar)\n",
    "    if abs(last.loc[1,'low'] - last.loc[2,'low'])/max(1e-9,last.loc[1,'low']) < 0.002:\n",
    "        patterns_found['tweezers_bottom'] += 1\n",
    "    if abs(last.loc[1,'high'] - last.loc[2,'high'])/max(1e-9,last.loc[1,'high']) < 0.002:\n",
    "        patterns_found['tweezers_top'] += 1\n",
    "\n",
    "    return dict(patterns_found)\n",
    "\n",
    "# --- Candle confidence scoring ---\n",
    "def candle_confidence_from_patterns(patterns):\n",
    "    \\\"\\\"\\\"Compute a 0-1 confidence score using stored stats and detected patterns.\\\"\\\"\\\"\n",
    "    stats = load_candle_stats()\n",
    "    # base score\n",
    "    score = 0.5\n",
    "    weight_sum = 0.0\n",
    "    for p, count in patterns.items():\n",
    "        if p not in stats:\n",
    "            continue\n",
    "        pat_stat = stats[p]\n",
    "        pat_score = pat_stat.get('success_rate', 0.5)\n",
    "        # weight patterns by occurrences and their historical reliability\n",
    "        w = min(1.0, count)  # occurrence weight (cap 1)\n",
    "        score += pat_score * w\n",
    "        weight_sum += w\n",
    "    if weight_sum > 0:\n",
    "        score = score / (1 + weight_sum)  # normalize into 0-1-ish range\n",
    "    # clip\n",
    "    return float(max(0.0, min(1.0, score)))\n",
    "\n",
    "# --- Reinforcement update ---\n",
    "def record_pattern_outcomes(patterns, outcome):\n",
    "    \\\"\\\"\\\"Update pattern stats : outcome True=win, False=loss\\\"\\\"\\\"\n",
    "    stats = load_candle_stats()\n",
    "    for p, cnt in patterns.items():\n",
    "        if p not in stats:\n",
    "            stats[p] = {\"success_rate\":0.5, \"count\":0, \"wins\":0, \"losses\":0}\n",
    "        stats[p]['count'] += cnt\n",
    "        if outcome:\n",
    "            stats[p]['wins'] += cnt\n",
    "        else:\n",
    "            stats[p]['losses'] += cnt\n",
    "        # recompute success_rate with smoothing\n",
    "        wins = stats[p]['wins']\n",
    "        losses = stats[p]['losses']\n",
    "        total = wins + losses\n",
    "        # Bayesian smoothing with prior 0.5, prior_weight=3\n",
    "        prior = 0.5; prior_w = 3\n",
    "        stats[p]['success_rate'] = (wins + prior*prior_w) / (total + prior_w) if total>0 else stats[p]['success_rate']\n",
    "    save_candle_stats(stats)\n",
    "    return stats\n",
    "\n",
    "# --- Helper integrate function ---\n",
    "def get_candle_confidence_for_tf(exchange, symbol, tf):\n",
    "    df = fetch_data(exchange, symbol, tf)\n",
    "    if df.empty:\n",
    "        return 0.5, {}\n",
    "    patterns = detect_patterns_from_df(df)\n",
    "    conf = candle_confidence_from_patterns(patterns)\n",
    "    return conf, patterns\n",
    "\n",
    "# --- Example usage ---\n",
    "# conf, patterns = get_candle_confidence_for_tf(exchange, 'BTCUSDT', '5M')\n",
    "# print(conf, patterns)\n",
    "\n",
    "# --- Utility to record a trade outcome after execution ---\n",
    "def record_trade_result(symbol, tf, patterns, entry_price, exit_price):\n",
    "    \\\"\\\"\\\"Call this after a trade is closed to update CLM learning stats.\\\"\\\"\\\"\n",
    "    win = (exit_price - entry_price) > 0\n",
    "    stats = record_pattern_outcomes(patterns, win)\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfea75b",
   "metadata": {},
   "source": [
    "\n",
    "## üîÅ Retrain Command (manual trigger)\n",
    "This cell adds a `/retrain`-style function you can call from the notebook to update **candle pattern stats**, **strategy weights**, and **timeframe alignment weights** based on historical performance stored in `/mnt/data/candle_stats.json` and recent trade logs.\n",
    "\n",
    "How to use on mobile:\n",
    "1. Open this notebook in Jupyter (or Colab).  \n",
    "2. Run the **Retrain** code cell below (it will run once, update weights, and save results).  \n",
    "3. Output and summary will print in the cell output.  \n",
    "4. Files created: `/mnt/data/retrain_log.json` (summary) and `/mnt/data/strategy_timeframe_weights.json` (updated weights).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9317699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, os, math, statistics, datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "CANDLE_STATS_PATH = \"/mnt/data/candle_stats.json\"\n",
    "RETRAIN_LOG_PATH = \"/mnt/data/retrain_log.json\"\n",
    "WEIGHTS_PATH = \"/mnt/data/strategy_timeframe_weights.json\"\n",
    "TRADE_HISTORY_PATH = \"/mnt/data/trade_history.json\"  # optional: used if exists\n",
    "\n",
    "def _safe_load(path, default):\n",
    "    if os.path.exists(path):\n",
    "        with open(path,\"r\") as f:\n",
    "            return json.load(f)\n",
    "    return default\n",
    "\n",
    "def _safe_save(path, obj):\n",
    "    with open(path,\"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def retrain_all(update_timeframe_weights=True, update_strategy_weights=True, smoothing=3):\n",
    "    \\\"\\\"\\\"Run a retraining pass:\n",
    "    - Reads candle pattern stats\n",
    "    - Updates smoothed success rates\n",
    "    - Generates/updates strategy and timeframe weights based on recent outcomes (trade_history if available)\n",
    "    \\\"\\\"\\\"\n",
    "    now = datetime.datetime.utcnow().isoformat()\n",
    "    stats = _safe_load(CANDLE_STATS_PATH, {})\n",
    "    if not stats:\n",
    "        print(\"‚ö†Ô∏è No candle_stats found at\", CANDLE_STATS_PATH)\n",
    "        return None\n",
    "\n",
    "    # 1) Recompute smoothed success rates (already updated by CLM during record_trade_result)\n",
    "    # Apply an additional smoothing to ensure stability\n",
    "    summary = {\"timestamp\": now, \"patterns\": {}, \"strategy_weights\": {}, \"timeframe_weights\": {}}\n",
    "\n",
    "    # Update pattern stats (apply small smoothing toward 0.5 prior)\n",
    "    for p, v in stats.items():\n",
    "        wins = v.get(\"wins\",0)\n",
    "        losses = v.get(\"losses\",0)\n",
    "        total = wins + losses\n",
    "        # Bayesian smoothing\n",
    "        prior = 0.5; prior_w = smoothing\n",
    "        success_rate = (wins + prior*prior_w) / (total + prior_w) if total>0 else v.get(\"success_rate\",0.5)\n",
    "        # store back\n",
    "        stats[p]['success_rate'] = round(success_rate,4)\n",
    "        summary[\"patterns\"][p] = {\"success_rate\": stats[p]['success_rate'], \"count\": stats[p].get(\"count\",0)}\n",
    "    _safe_save(CANDLE_STATS_PATH, stats)\n",
    "\n",
    "    # 2) Strategy & timeframe weight updates (heuristic if trade history exists)\n",
    "    # Default strategies and timeframes (will extend if trade_history contains more)\n",
    "    default_strategies = [\"breakout\",\"mean_reversion\",\"momentum_reversal\"]\n",
    "    default_timeframes = [\"30s\",\"5M\",\"1M\",\"1H\",\"4H\",\"1D\",\"1W\",\"1M\",\"3M\",\"6M\",\"1Y\"]\n",
    "\n",
    "    # initialize weights\n",
    "    strategy_weights = {s: 1.0 for s in default_strategies}\n",
    "    timeframe_weights = {tf: 1.0 for tf in default_timeframes}\n",
    "\n",
    "    # If trade history exists, use it to adjust weights\n",
    "    trade_history = _safe_load(TRADE_HISTORY_PATH, [])\n",
    "    if trade_history:\n",
    "        # Expected trade_history entry: {\"symbol\",\"tf\",\"strategy\",\"entry\",\"exit\",\"win\":bool, \"timestamp\"}\n",
    "        strat_perf = defaultdict(lambda: {\"wins\":0,\"losses\":0})\n",
    "        tf_perf = defaultdict(lambda: {\"wins\":0,\"losses\":0})\n",
    "        for t in trade_history:\n",
    "            s = t.get(\"strategy\")\n",
    "            tf = t.get(\"tf\")\n",
    "            win = bool(t.get(\"win\"))\n",
    "            if s:\n",
    "                if win: strat_perf[s][\"wins\"] += 1\n",
    "                else: strat_perf[s][\"losses\"] += 1\n",
    "            if tf:\n",
    "                if win: tf_perf[tf][\"wins\"] += 1\n",
    "                else: tf_perf[tf][\"losses\"] += 1\n",
    "\n",
    "        # Convert to weighted scores\n",
    "        for s, perf in strat_perf.items():\n",
    "            w = (perf[\"wins\"] + smoothing*0.5) / (perf[\"wins\"]+perf[\"losses\"]+smoothing)\n",
    "            strategy_weights[s] = round(w,4)\n",
    "        for tf, perf in tf_perf.items():\n",
    "            w = (perf[\"wins\"] + smoothing*0.5) / (perf[\"wins\"]+perf[\"losses\"]+smoothing)\n",
    "            timeframe_weights[tf] = round(w,4)\n",
    "\n",
    "    # Normalize weights to 0-1\n",
    "    max_sw = max(strategy_weights.values()) if strategy_weights else 1.0\n",
    "    strategy_weights = {k: round(v/max_sw,4) for k,v in strategy_weights.items()}\n",
    "\n",
    "    max_tw = max(timeframe_weights.values()) if timeframe_weights else 1.0\n",
    "    timeframe_weights = {k: round(v/max_tw,4) for k,v in timeframe_weights.items()}\n",
    "\n",
    "    # Save weights\n",
    "    weights = {\"strategy_weights\": strategy_weights, \"timeframe_weights\": timeframe_weights, \"generated_at\": now}\n",
    "    _safe_save(WEIGHTS_PATH, weights)\n",
    "    summary[\"strategy_weights\"] = strategy_weights\n",
    "    summary[\"timeframe_weights\"] = timeframe_weights\n",
    "\n",
    "    # 3) Log retrain summary\n",
    "    _safe_save(RETRAIN_LOG_PATH, summary)\n",
    "    print(\"‚úÖ Retrain complete. Summary saved to\", RETRAIN_LOG_PATH)\n",
    "    return summary\n",
    "\n",
    "# Helper to call from other code (mimics /retrain)\n",
    "def handle_retrain_command():\n",
    "    print(\"Running retrain...\")\n",
    "    summary = retrain_all()\n",
    "    if summary:\n",
    "        print(\"Retrain summary:\")\n",
    "        print(json.dumps(summary, indent=2))\n",
    "    return summary\n",
    "\n",
    "# Expose as global for notebook usage\n",
    "_retrain_available = True\n",
    "print(\"Retrain utility loaded. Call handle_retrain_command() to retrain (manual trigger).\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNTcV1EJ5UUwwFvFbwkIpbX",
   "include_colab_link": true,
   "mount_file_id": "1cfMu60bMbUB1v0V29z3Cxw7K8m4iveQB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
